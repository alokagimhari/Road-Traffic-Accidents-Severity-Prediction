# -*- coding: utf-8 -*-
"""DM_group.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MMgPNWeEARTmPlv5UCxSUoXrmZa1hkci

## **Road Traffic Accidents Severity Prediction**

### **Data Preprocessing**

##### ***Import Necessary Libraries***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats
import seaborn as sns

"""##### ***Load the Dataset***"""

data = pd.read_csv('RTA Dataset.csv')

data.head()

"""##### ***Handle Missing Values***"""

# Check for missing values
missing_values = data.isnull().sum()
print(missing_values)

#dropping columns which has more than 2500 missing values and Time column
data.drop(['Service_year_of_vehicle','Defect_of_vehicle','Work_of_casuality', 'Fitness_of_casuality','Time'], axis = 1, inplace = True)

# List of columns to drop if they have NaN values
columns_to_drop = ['Vehicle_driver_relation', 'Driving_experience','Type_of_vehicle', 'Owner_of_vehicle','Area_accident_occured','Lanes_or_Medians','Road_allignment','Types_of_Junction','Road_surface_type','Type_of_collision','Vehicle_movement','Educational_level']

# Drop rows with NaN values in the specified columns
for column_name in columns_to_drop:
    if column_name in data.columns:
        data = data.dropna(subset=[column_name])
    else:
        print(f"Column '{column_name}' not found in the DataFrame.")

"""#**EDA**

#####**Numerical Data Analysis**
"""

data.hist(layout=(1,6), figsize=(30,5))
plt.show()

data['Number_of_casualties'].value_counts()

plt.figure(figsize=(10,7))
sns.boxplot(data=data, y='Number_of_vehicles_involved', x='Number_of_casualties')
plt.show()

sns.boxplot(data=data, y='Number_of_vehicles_involved')
plt.show()

data['Number_of_vehicles_involved']

sns.scatterplot(x=data['Number_of_vehicles_involved'], y=data['Number_of_casualties'])
plt.show()

sns.pairplot(data[['Number_of_vehicles_involved','Number_of_casualties']])
plt.show()

# Create a bar plot
plt.figure(figsize=(12, 8))
sns.countplot(data=data, x='Educational_level')
plt.title('Distribution of Categories')
plt.xlabel('Educational_level')
plt.ylabel('Count')
plt.show()

"""#####**Categorical Data Analysis**"""

plt.figure(figsize=(8,6))
plt.pie(x=data['Accident_severity'].value_counts().values,
        labels=data['Accident_severity'].value_counts().index,
        autopct='%2.2f%%')
plt.show()

# creating a facet grid with columns as survived=0 and survived=1
grid = sns.FacetGrid(data=data, col='Accident_severity', height=4, aspect=1, sharey=False)
# mapping bar plot and the data on to the grid
grid.map(sns.countplot, 'Number_of_vehicles_involved', palette=['green', 'purple', 'brown'])
plt.show()

"""##### ***Handle Outliers***

**Identify Outliers**
"""

# Calculate the z-scores for numerical columns
from scipy import stats

z_scores = np.abs(stats.zscore(data.select_dtypes(include=np.number)))
threshold = 3
outlier_rows, outlier_columns = np.where(z_scores > threshold)

# IQR method for outlier detection
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Detect outliers
outliers = ((data < lower_bound) | (data > upper_bound)).any(axis=1)

import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(data, kde=True)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=data)
plt.show()

"""**Removing Outliers**"""

# Remove rows containing outliers
data = data[~outliers]
data.head()

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=data)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

#sns.boxplot(data=data)
#plt.show()
sns.histplot(data, kde=True)
plt.show()

"""# Feature Reduction"""

data.dtypes

categorical=[i for i in data.columns if data[i].dtype=='O']

# Create a new DataFrame for label encoding
df1=pd.DataFrame()
# Initialize the Label Encoder
le = LabelEncoder()

# Apply label encoding to each categorical column except the target 'Accident_severity'
for i in categorical:
    if i != 'Accident_severity':
        df1[i] = le.fit_transform(data[i])

data.head()

df1.head()

#confirming the data type
df1.info()

plt.figure(figsize=(30,20))
sns.set(font_scale=1)
sns.heatmap(df1.corr(), annot=True)

#import chi2 test
from sklearn.feature_selection import chi2
f_p_values=chi2(df1,data['Accident_severity'])

#f_p_values will return Fscore and pvalues
f_p_values

df1.head()

#for better understanding and ease of access adding them to a new dataframe
f_p_values1=pd.DataFrame({'features':df1.columns, 'Fscore': f_p_values[0], 'Pvalues':f_p_values[1]})
f_p_values1

#since we want lower Pvalues we are sorting the features
f_p_values1.sort_values(by='Pvalues',ascending=True)

df1.columns

#after evaluating we are removing lesser important columns and storing to a new data frame
df2=data.drop(['Day_of_week', 'Age_band_of_driver', 'Sex_of_driver',
       'Educational_level', 'Driving_experience', 'Owner_of_vehicle', 'Area_accident_occured',
       'Lanes_or_Medians', 'Road_allignment',
       'Road_surface_type', 'Road_surface_conditions', 'Light_conditions',
       'Weather_conditions', 'Type_of_collision', 'Vehicle_movement',
       'Casualty_class', 'Sex_of_casualty', 'Age_band_of_casualty',
       'Casualty_severity', 'Pedestrian_movement', 'Cause_of_accident'],axis=1)
df2.head()

df2.shape

df2.head()

df2.columns

data.columns

# Define the list of categorical columns
categorical = ['Vehicle_driver_relation', 'Type_of_vehicle', 'Types_of_Junction',
       'Number_of_vehicles_involved', 'Number_of_casualties',
       'Accident_severity']

# Create a new DataFrame for label encoding
df3=pd.DataFrame()

# Initialize the Label Encoder
le = LabelEncoder()


# Apply label encoding to each categorical column except the target 'Accident_severity'

for i in categorical:
    if i != 'Accident_severity':
        df3[i] = le.fit_transform(df2[i])

df2.head()

df3.head()

X = df3[['Vehicle_driver_relation', 'Type_of_vehicle', 'Types_of_Junction',
       'Number_of_vehicles_involved', 'Number_of_casualties']]
y = df2["Accident_severity"]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

"""#Model Creation

###KNN
"""

#KNN model alg
from sklearn.neighbors import KNeighborsClassifier
model_KNN=KNeighborsClassifier(n_neighbors=5)
model_KNN.fit(x_train,y_train)

y_KNN=model_KNN.predict(x_test)
# Print all predicted values
for prediction in y_KNN:
    print(prediction)

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,ConfusionMatrixDisplay
matrix_KNN=confusion_matrix(y_test,y_KNN)
print(matrix_KNN,'\n')
print(ConfusionMatrixDisplay.from_predictions(y_test,y_KNN))
accuracy_KNN=accuracy_score(y_test,y_KNN)
print(accuracy_KNN,'\n')
report_KNN=classification_report(y_test,y_KNN)
print(report_KNN)

"""###Naive Bayes"""

#naive bayes model alg
from sklearn.naive_bayes import MultinomialNB
model_naive=MultinomialNB()
model_naive.fit(x_train,y_train)

y_naive=model_naive.predict(x_test)
# Print all predicted values
for prediction in y_naive:
    print(prediction)

matrix_naive=confusion_matrix(y_test,y_naive)
print(matrix_naive,'\n')
print(ConfusionMatrixDisplay.from_predictions(y_test,y_naive))
accuracy_naive=accuracy_score(y_test,y_naive)
print(accuracy_naive,'\n')
report_naive=classification_report(y_test,y_naive)
print(report_naive)

"""###Decision Tree"""

#Decision Tree model alg
from sklearn.tree import DecisionTreeClassifier
model_dec=DecisionTreeClassifier(criterion='entropy')
model_dec.fit(x_train,y_train)

y_dec=model_dec.predict(x_test)
# Print all predicted values
for prediction in y_dec:
    print(prediction)

matrix_dec=confusion_matrix(y_test,y_dec)
print(matrix_dec,'\n')
print(ConfusionMatrixDisplay.from_predictions(y_test,y_dec))
accuracy_dec=accuracy_score(y_test,y_dec)
print(accuracy_dec,'\n')
report_dec=classification_report(y_test,y_dec)
print(report_dec)

"""Compare"""

alg=['KNN','Naive Bayes','Decision Tree']
acc=[accuracy_KNN,accuracy_naive,accuracy_dec]
Accuracy_Scores=pd.DataFrame({'Algorithms':alg, 'Accuracy': acc})
Accuracy_Scores['Accuracy']=Accuracy_Scores['Accuracy']*100
Accuracy_Scores

#sorting models based on their accuracy score
Accuracy_Scores.sort_values(by='Accuracy',ascending=False)

ax = sns.barplot(x='Algorithms', y='Accuracy',
                 palette='muted', data=Accuracy_Scores.sort_values(by='Accuracy',ascending=False),
                 errwidth=0)
for i in ax.containers:
    ax.bar_label(i,)

from ipywidgets import interact, widgets, Button, Output
import io
import IPython.display

# Create an output widget to display the prediction result
output = Output()

@interact
def predict_severity(
    Vehicle_driver_relation=widgets.Dropdown(options=['Employee', 'Owner', 'Other', 'Unknown']),
    Type_of_vehicle=widgets.Dropdown(options=['Public', 'Automobile', 'Lorry (41?100Q)', 'Public (13?45 seats)', 'Lorry (11?40Q)', 'Long lorry', 'Public (12 seats)', 'Taxi', 'Pick up upto 10Q', 'Stationwagen', 'Ridden horse', 'Other', 'Bajaj', 'Motorcycle', 'Special vehicle', 'Turbo', 'Bicycle']),
    Types_of_Junction=widgets.Dropdown(options=['No junction', 'Y Shape', 'Crossing', 'O Shape', 'Other', 'Unknown', 'T Shape', 'X Shape']),
    Number_of_vehicles_involved=widgets.IntSlider(min=1, max=10, step=1, value=5),
    Number_of_casualties=widgets.IntSlider(min=1, max=10, step=1, value=5)
):
    button = Button(description="Submit")

    # Function to handle the submit button click
    def on_button_click(b):
        with output:
            # Use the selected values to make a prediction
            user_input = []

            for value in [Vehicle_driver_relation, Type_of_vehicle, Types_of_Junction]:
                if value in label_encoder.classes_:
                    user_input.append(label_encoder.transform([value])[0])
                else:
                    # Handle unknown or unexpected values here
                    print(f'Warning: Unknown value "{value}". You may want to handle this case.')

            user_input.extend([Number_of_vehicles_involved, Number_of_casualties])

            if len(user_input) == 5:
                prediction = model_KNN.predict([user_input])
                print(f'Predicted Accident Severity: {prediction[0]}')

    button.on_click(on_button_click)
    display(button)

# Display the prediction result in the output widget
display(output)